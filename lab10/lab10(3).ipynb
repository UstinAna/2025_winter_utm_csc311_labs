{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2a4QUGVSNwE"
      },
      "source": [
        "# CSC311 Lab 10: Clustering via Bernoulli Mixture Models\n",
        "\n",
        "In this lab, we will build a Bernoulli Mixture Model to cluster\n",
        "movie reviews. We will use the same movie reviews data set as in Lab 9.\n",
        "However, we will *not* use the positive/negative labels. Instead,\n",
        "we will analyze the reviews themselves to see whether there are\n",
        "interesting structure in the reviews, in the form of clusters.\n",
        "\n",
        "By the end of this lab , you will be able to:\n",
        "\n",
        "1. Explain the connection between the Bernoulli Mixture Model and the Naive Bayes model from week 8.\n",
        "2. Explain the connection between the Bernoulli Mixture Model and the Gaussian Mixture model from lecture 10.\n",
        "3. Apply the E-M algorithm to fit a BMM model to perform clustering over Bernoulli variables.\n",
        "4. Track the progress of the E-M algorithm by tracking the MLE.\n",
        "5. Analyze the results of the clustering by manually observing the clusters.\n",
        "\n",
        "Please work in groups of 1-2 during the lab.\n",
        "\n",
        "## Submission\n",
        "\n",
        "If you are working with a partner, start by creating a group on Markus.\n",
        "If you are working alone,\n",
        "click \"Working Alone\".\n",
        "\n",
        "Submit the ipynb file `lab10.ipynb` on Markus\n",
        "**containing all your solutions to the Graded Task**s.\n",
        "Your notebook file must contain your code **and outputs** where applicable,\n",
        "including printed lines and images.\n",
        "Your TA will not run your code for the purpose of grading.\n",
        "\n",
        "For this lab, you should submit the following:\n",
        "\n",
        "\n",
        "- Part 2. your implementation of the `e_step` function (3 points).\n",
        "- Part 2. your implementation of the `m_step` function (3 points).\n",
        "- Part 2. your implementation of the `em_bmm` function (1 points).\n",
        "- Part 3. your code and interpretation of the results of running `em_bmm` on all data, with 2 clusters (2 points)\n",
        "- Part 3. your code and interpretation of the results of running `em_bmm` on positive reviews, with 5 clusters (1 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYi-jAJVSNwH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNTy8ydtSNwI"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "Data is a variation of the one from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews,\n",
        "pre-processed so that only 1000 words are in the training/test set.\n",
        "\n",
        "## Part 1. Data\n",
        "\n",
        "We will use the same movie review data set as in lab 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P9mCVQkSNwI",
        "outputId": "ee4b797c-9db6-460e-a315-324869d55325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-23 00:16:19--  https://www.cs.toronto.edu/~lczhang/311/lab09/trainvalid.csv\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1464806 (1.4M) [text/csv]\n",
            "Saving to: ‘trainvalid.csv’\n",
            "\n",
            "trainvalid.csv      100%[===================>]   1.40M  5.59MB/s    in 0.3s    \n",
            "\n",
            "2025-03-23 00:16:19 (5.59 MB/s) - ‘trainvalid.csv’ saved [1464806/1464806]\n",
            "\n",
            "--2025-03-23 00:16:19--  https://www.cs.toronto.edu/~lczhang/311/lab09/test.csv\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491538 (480K) [text/csv]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>] 480.02K  2.59MB/s    in 0.2s    \n",
            "\n",
            "2025-03-23 00:16:20 (2.59 MB/s) - ‘test.csv’ saved [491538/491538]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download tutorial data files.\n",
        "!wget https://www.cs.toronto.edu/~lczhang/311/lab09/trainvalid.csv\n",
        "!wget https://www.cs.toronto.edu/~lczhang/311/lab09/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wom2v1HHSNwJ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Training/Validation set\n",
        "trainfile = \"trainvalid.csv\"\n",
        "data = list(csv.reader(open(trainfile)))\n",
        "\n",
        "# Build the vocabulary\n",
        "vocab = set()\n",
        "for review, label in csv.reader(open(trainfile)):\n",
        "    words = review.split()\n",
        "    for w in words:\n",
        "        vocab.add(w)\n",
        "vocab = list(vocab) # len(vocab) == 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxmHKjWdSNwK"
      },
      "source": [
        "**Task**: Use the function `make_bow` that you wrote in lab 9 to create a\n",
        "data matrix consisting of bag-of-word features. We will then create three\n",
        "matrices: one for all reviews, one for only positive reviews, and one\n",
        "for only negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqsi7LdQSNwL"
      },
      "outputs": [],
      "source": [
        "def make_bow(data, vocab):\n",
        "    \"\"\"\n",
        "    Produce the bag-of-word representation of the data, along with a vector\n",
        "    of labels. You *may* use loops to iterate over `data`. However, your code\n",
        "    should not take more than O(len(data) * len(vocab)) to run.\n",
        "\n",
        "    Parameters:\n",
        "        `data`: a list of `(review, label)` pairs, like those produced from\n",
        "                `list(csv.reader(open(\"trainvalid.csv\")))`\n",
        "        `vocab`: a list consisting of all unique words in the vocabulary\n",
        "\n",
        "    Returns:\n",
        "        `X`: A data matrix of bag-of-word features. This data matrix should be\n",
        "             a numpy array with shape [len(data), len(vocab)].\n",
        "             Moreover, `X[i,j] == 1` if the review in `data[i]` contains the\n",
        "             word `vocab[j]`, and `X[i,j] == 0` otherwise.\n",
        "        `t`: A numpy array of shape [len(data)], with `t[i] == 1` if\n",
        "             `data[i]` is a positive review, and `t[i] == 0` otherwise.\n",
        "    \"\"\"\n",
        "    X = np.zeros([len(data), len(vocab)])\n",
        "    t = np.zeros([len(data)])\n",
        "\n",
        "    # TODO: fill in the appropriate values of X and t --- DONE ---\n",
        "    for i, (review, label) in enumerate(data):\n",
        "        words = review.split()\n",
        "        for w in words:\n",
        "            if w in vocab:\n",
        "                X[i, vocab.index(w)] = 1\n",
        "        t[i] = 1 if label == 'positive' else 0\n",
        "\n",
        "    return X, t\n",
        "\n",
        "# Data matrix with all reviews in trainvalid.csv\n",
        "X_all, t_all = make_bow(data, vocab)\n",
        "\n",
        "# Data matrix with only positive reviews\n",
        "data_pos = [data[i] for i in np.where(t_all == 1)[0]] # actual review text\n",
        "X_pos = X_all[t_all == 1]                             # data matrix\n",
        "\n",
        "# Data matrix with only negative reviews\n",
        "data_neg = [data[i] for i in np.where(t_all == 0)[0]] # actual review text\n",
        "X_neg = X_all[t_all == 0]                             # data matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3XcXF_4SNwL"
      },
      "source": [
        "## Part 2. Bernoulli Mixture Model\n",
        "\n",
        "A Bernoulli Mixture Model is a finite mixture of random binary, independent features.\n",
        "$$p({\\bf x})=  \\sum_{k=1}^K p({\\bf x} | z=k) \\ P(z=k) = (\\sum_{k=1}^K \\prod_{j=1}^D p(x_j | z=k) ) P(z=k)$$\n",
        "Where $p(z)$ describes the distribution of a categorical random variable,\n",
        "and each $p(x_j | z=k)$ describes the distribution of a Bernoulli random variable.\n",
        "The parameters of our model include $\\pi_k=P(z=k)$ (if there are $K$ classes,\n",
        "then we have parameters $\\pi_1$, $\\pi_2$, \\dots, $\\pi_{K-1}$), and\n",
        "$\\theta_{jk}=p(x_j=1 |z=k)$ (of which there are $DK$ in total).\n",
        "\n",
        "Note the similarities and differences between a BMM v.s.\n",
        "a mixture of Gaussians described in class (written MoG, also Gaussian Mixture Model or GMM).\n",
        "In both mixture models, we have\n",
        "$$p({\\bf x})= p({\\bf x} | z=k) \\ P(z=k)$$,\n",
        "with $P(z)$ being a categorical distribution. The difference is that in\n",
        "a mixture of Gaussians, $p({\\bf x} | z=k)$ is a Gaussian, whereas  in a\n",
        "Bernoulli mixture model, $p({\\bf x} | z=k) = \\prod_{j=1}^D p(x_j | z=k)$.\n",
        "That is, each $p({\\bf x} | z=k)$ consists of $D$ different conditionally\n",
        "independent Bernoullis $p(x_j | z=k)$, where ${\\bf x} \\in \\mathbb{R}^D$.\n",
        "\n",
        "The decomposition of\n",
        "$p({\\bf x})= \\sum_{k=1}^K (\\prod_{j=1}^D p(x_j | z=k) ) P(z=k)$\n",
        "is similar to Naive Bayes. However,\n",
        "unlike in the Naive Bayes lab, our random variable $z$ is **not observed**. Thus,\n",
        "$z$ is called a **latent variable**.\n",
        "\n",
        "<!--\n",
        "Still, we can marginalize out $z$ to write\n",
        "down the likelihood of our data:\n",
        "\\begin{align*}\n",
        "\\ell(\\{\\pi_k, \\theta_{jk}\\})\n",
        "    &= \\sum_{k=1}^K \\sum_{i=1}^N \\log\\Big\\{ p({\\bf x}^{(i)}|z^{(i)})p(z^{(i)}=k)\\Big\\}\\\\\n",
        "    &= \\sum_{k=1}^K \\sum_{i=1}^N \\log \\Big\\{p(z^{(i)}=k) \\prod_{j=1}^D p(x_j^{(i)} | z^{(i)}=k) \\Big\\}\\\\\n",
        "    &= \\sum_{k=1}^K \\sum_{i=1}^N \\left[ \\log p(z^{(i)}=k) + \\sum_{j=1}^D \\log p(x_j^{(i)} | z^{(i)}=k) \\right] \\\\\n",
        "    &= \\sum_{k=1}^K \\sum_{i=1}^N \\log p(z^{(i)}=k) + \\sum_{k=1}^K \\sum_{j=1}^D \\sum_{i=1}^N \\log p(x_j^{(i)} | z^{(i)}=k)\n",
        "\\end{align*}\n",
        "-->\n",
        "\n",
        "In this section, we will fit the parameters of this BMM model to maximize\n",
        "the likelihood of our movie review data.\n",
        "\n",
        "Because $z$ is latent, we will need to use the Expectation-Maximization (E-M) algorithm.\n",
        "EM is an optimization approach where we alternatively optimize the\n",
        "responsibilities $r_k^{(i)}= P(z^{(i)}=k | {\\bf x}^{(i)}; \\theta, \\pi)$ given the parameters,\n",
        "and optimize the parameters given the cluster responsibilities $r_k^{(i)}$ for each data point $i$\n",
        "and cluster $k$.\n",
        "\n",
        "**Graded Task**: The \"E\" step of the Expectation-Maximization Algorithm\n",
        "assign the **responsibility** $r_k^{(i)}$ of component $k$ for data point $i$ using the posterior probability:\n",
        "$$r_k^{(i)}= P(z^{(i)}=k | {\\bf x}^{(i)}; \\theta, \\pi)$$\n",
        "Complete the function `e_step` which performs this computation.\n",
        "You **may** use loops, but minimizing the use of loops would help make your code run faster.\n",
        "\n",
        "If you are not sure where to start, a good place is to review the \"E\" step for\n",
        "the Gaussian mixture model. Computation, the \"E\" step for the GMM is the *inference*\n",
        "stage of a Gaussian Discriminate Analysis model. Likewise, the \"E\" step of our\n",
        "BMM model is computationally the same as the *inference* stage of a Naive Bayes\n",
        "model. If this analogy doesn't makes sense, please ask!\n",
        "Once this analogy makes sense, it should be clear what computation needs to be\n",
        "done, and how this math relates to your work from lab 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMc5QehxSNwM",
        "outputId": "343faf7c-842d-498e-f9a5-ce9c0ca480e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.81818182, 0.18181818],\n",
              "       [0.11111111, 0.88888889]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def e_step(X, pi, theta):\n",
        "    \"\"\"\n",
        "    Perform the \"E\" step of the E-M Algorithm for a BMM.\n",
        "    In other words, given the data matrix `X` and estimates to the\n",
        "    parameters `theta` and `pi`, estimate $P(z=k|{\\bf x})$ for each\n",
        "    ${\\bf x}$ in the data matrix.\n",
        "\n",
        "    Parameters:\n",
        "        `X` - a data matrix of bag-of-word features of shape [N, D],\n",
        "              where N is the number of data points and D is the vocabulary size.\n",
        "              X[i,j] should be either 0 or 1. Produced by the make_bow() function.\n",
        "        `pi` - a vector of shape [K], where `pi[k]` corresponds to\n",
        "              an estimate of the parameter $\\pi_{k} = P(z=k)$.\n",
        "              Precondition: `np.sum(pi) = 1` so that the $\\pi_k$s describe a\n",
        "              probability distribution.\n",
        "        `theta` - a matrix of shape [D, K], where `theta[j, k]` corresponds to\n",
        "              an estimate of the parameter $\\theta_{jk} = P(x_j = 1 | z=k)$\n",
        "\n",
        "    Returns:\n",
        "        `R` - a matrix of shape [N, K], where `R[j, k]` corresponds to the\n",
        "              value $P(z^{(j)}=k| {\\bf x^{(j)}})$ computed using the estimated\n",
        "              parameters `theta` and `pi`.\n",
        "              Each row of `R` should sum up to 1, i.e. `sum(R[j,:]) == 1`.\n",
        "    \"\"\"\n",
        "    N, D = X.shape\n",
        "    D, K = theta.shape\n",
        "    R = np.zeros([N, K])\n",
        "\n",
        "    # TODO: fill in the elements of R\n",
        "    # Remember the log trick that we used to avoid computing a product\n",
        "    # of small numbers, from lab 9.\n",
        "\n",
        "    # --- DONE ---\n",
        "    for n in range(N):\n",
        "        for k in range(K):\n",
        "            # Initialize with log(pi_k)\n",
        "            log_prob = np.log(pi[k])\n",
        "\n",
        "            # Add log probabilities for each feature\n",
        "            for d in range(D):\n",
        "                if X[n, d] == 1:\n",
        "                    log_prob += np.log(theta[d, k])\n",
        "                else:\n",
        "                    log_prob += np.log(1 - theta[d, k])\n",
        "\n",
        "            # Store the unnormalized log probability\n",
        "            R[n, k] = log_prob\n",
        "\n",
        "        # Convert from log probabilities to actual probabilities\n",
        "        # Subtract max for numerical stability before exp\n",
        "        log_max = np.max(R[n])\n",
        "        R[n] = np.exp(R[n] - log_max)\n",
        "\n",
        "        # Normalize to get valid probabilities that sum to 1\n",
        "        R[n] = R[n] / np.sum(R[n])\n",
        "\n",
        "    return R\n",
        "\n",
        "# Test example with N=2 movie reviews, D=1 words, K=2 clusters\n",
        "X_basic_check = np.array([[1], [0]]) # first data point has the word present\n",
        "                                     # second data point has the word absent\n",
        "pi_basic_check = np.array([0.5, 0.5]) # both clusters have equal probability\n",
        "theta_basic_check = np.array([[0.9 ,  # first cluster has P(word present|cluster) = 0.9\n",
        "                               0.2]]) # second cluster has P(word present|cluster) = 0.2\n",
        "\n",
        "# Please include the output of the below call in your submission.\n",
        "# Think: what do the 4 results numbers here mean? You should\n",
        "# see that the first data point has a higher probability of\n",
        "# being in the first cluster (vs the second cluster), and vice-versa\n",
        "# for the second data point. Why would this make sense?\n",
        "# (You do not need to write a response. The question is here to\n",
        "# help you interpret what this function is doing.)\n",
        "e_step(X_basic_check, pi_basic_check, theta_basic_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEiqs6eYSNwN"
      },
      "source": [
        "**Graded Task**: The \"M\" step of the Expectation-Maximization Algorithm\n",
        "computes estimates of $\\pi$ and $\\theta_{jk}$ via maximum likelihood,\n",
        "where each the parameters for each class $k$ is fit with a weighted dataset.\n",
        "The weights are proportional to the responsibilities.\n",
        "Complete the function `m_step` which performs this computation.\n",
        "You **may** use loops, but minimizing the use of loops would help make your code run faster.\n",
        "\n",
        "If you are not sure where to start, a good place is to review the \"M\" step for\n",
        "the Gaussian mixture model. Computation, the \"M\" step for the GMM is\n",
        "a slight variation of the *learning* stage of a Gaussian Discriminate Analysis model.\n",
        "Likewise, the \"E\" step of our BMM model is computationally very similar as the\n",
        "*learning* stage of a Naive Bayes model (except that $r_j^{(i)}$ is now continuous\n",
        "rather than being exactly 0 or 1).\n",
        "Once again, if this analogy doesn't makes sense, please ask!\n",
        "And when this analogy makes sense, it should be clear what computation\n",
        "needs to be done, and how this math relates to your work from lab 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z42M5MOySNwO",
        "outputId": "c69ae6a5-d136-4f40-f77e-81758b869d46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.6, 0.4]), array([[0.58333333, 0.375     ]]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def m_step(X, R):\n",
        "    \"\"\"\n",
        "    Perform for a BMM the \"M\" step of the E-M Algorithm for a BMM.\n",
        "    In other words, given the data matrix `X` and estimates to the\n",
        "    parameters `theta` and `pi`, estimate $P(z=k|{\\bf x})$ for each ${\\bf x}$ in the\n",
        "    data matrix.\n",
        "\n",
        "    Parameters:\n",
        "        `X` - a data matrix of bag-of-word features of shape [N, D],\n",
        "              where N is the number of data points and D is the vocabulary size.\n",
        "              X[i,j] should be either 0 or 1. Produced by the make_bow() function.\n",
        "        `R` - a matrix responsibilities of shape [N, K], where `R[j, k]` corresponds\n",
        "              to the value $P(z^{(j)}=k| {\\bf x^{(j)}})$ computed during the e_step.\n",
        "              Precondition: Each row of `R` sums to 1, i.e. `sum(R[j,:]) == 1`\n",
        "\n",
        "    Returns:\n",
        "        `theta` - a matrix of shape [D, K], where `theta[j, k]` corresponds to\n",
        "              the MLE estimate of the parameter $\\theta_{jk} = p(x_j = 1 | z=k)$\n",
        "        `pi` - a vector of shape [K], where `pi[k]` corresponds to\n",
        "              the MLE estimate of the parameter $\\pi_{k} = P(z=k)$.\n",
        "              We should have `np.sum(pi) = 1` so that the $\\pi_k$s describe a\n",
        "              probability distribution.\n",
        "    \"\"\"\n",
        "    N, D = X.shape\n",
        "    N, K = R.shape\n",
        "\n",
        "    # Calculate pi (cluster probabilities) --- DONE ---\n",
        "    # pi_k = sum of responsibilities for cluster k / total number of data points\n",
        "    pi = np.sum(R, axis=0) / N\n",
        "\n",
        "    # Calculate theta (word probabilities given cluster)\n",
        "    theta = np.zeros([D, K]) # TODO: fill this!\n",
        "\n",
        "     # For each feature and cluster\n",
        "    for d in range(D):\n",
        "        for k in range(K):\n",
        "            # Weighted count of word occurrences in cluster k\n",
        "            numerator = np.sum(X[:, d] * R[:, k])\n",
        "            # Sum of responsibilities for cluster k\n",
        "            denominator = np.sum(R[:, k])\n",
        "            # Probability of word d being present in cluster k\n",
        "            theta[d, k] = numerator / denominator\n",
        "\n",
        "    return (pi, theta)\n",
        "\n",
        "# Test example with N=2 movie reviews, D=1 words, K=2 clusters\n",
        "X_basic_check = np.array([[1], [0]]) # first data point has the word present\n",
        "                                     # second data point has the word absent\n",
        "R_basic_check = np.array([[0.7, 0.3],\n",
        "                          [0.5, 0.5]])\n",
        "\n",
        "# Please include the output of the below call in your submission.\n",
        "# Think: you should see that the \"pi\"s are such that the first\n",
        "# cluster is a tad more likely to be observed. Why does this\n",
        "# make sense? You should also see that the estimate for\n",
        "# P(word present|cluster 1) is higher than P(word present|cluster 2).\n",
        "# Why does this also make sense? (You do not need to write a response.\n",
        "# The question is here to help you interpret what this function is doing.)\n",
        "m_step(X_basic_check, R_basic_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6XiZUpjSNwP"
      },
      "source": [
        "**Graded Task**: Complete the function `em_bmm` by calling the functions `e_step`\n",
        "and `m_step` that you wrote previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xculC2WPSNwP"
      },
      "outputs": [],
      "source": [
        "def em_bmm(X, K=5, num_iter=10):\n",
        "    \"\"\"\n",
        "    Use the E-M algorithm to compute parameters `theta` and `pi` of a\n",
        "    Bernouli Mixture Model fit on the data `X`.\n",
        "\n",
        "    Parameters:\n",
        "        `X` - a data matrix of bag-of-word features of shape [N, D],\n",
        "              where N is the number of data points and D is the vocabulary size.\n",
        "              X[i,j] should be either 0 or 1. Produced by the make_bow() function.\n",
        "        `K` - number of classes (i.e. number of Bernouli Mixtures in the model)\n",
        "        `num_iter` - number of iterations to run the E-M algorithm\n",
        "\n",
        "    Returns:\n",
        "        `theta` - a matrix of shape [D, K], where `theta[j, k]` corresponds to\n",
        "              the E-M estimate of the parameter $\\theta_{jk} = P(x_j = 1 | z=k)$\n",
        "        `pi` - a vector of shape [K], where `pi[k]` corresponds to\n",
        "              the E-M estimate of the parameter $\\pi_{k} = P(z=k)$.\n",
        "              We should have `np.sum(pi) = 1` so that the $\\pi_k$s describe a\n",
        "              probability distribution.\n",
        "    \"\"\"\n",
        "    N, vocab_size = X.shape\n",
        "\n",
        "    pi = np.ones([K]) * (1/K)  # start with equal class probabilities\n",
        "    theta = np.random.rand(vocab_size, K) / 10 # initialize p(x_j|z) to be between 0 and 0.1\n",
        "\n",
        "    for j in range(num_iter):\n",
        "        # e-step\n",
        "        # TODO - what needs to be computed here?\n",
        "        # Calculate responsibilities (posterior probabilities of each data point belonging to each cluster)\n",
        "        R = e_step(X, pi, theta)\n",
        "\n",
        "        # m-step\n",
        "        # TODO - what needs to be computed here?\n",
        "        # Update parameters based on the calculated responsibilities\n",
        "        pi, theta = m_step(X, R)\n",
        "\n",
        "    return pi, theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITkX-NE1SNwP"
      },
      "source": [
        "## Part 3. Clustering\n",
        "\n",
        "In this section, we will use the `em_bmm` to cluster our movie reviews. We will\n",
        "*not* use the positive/negative reviews as labels, and the clusters that we find\n",
        "may or may not correspond to easily interpretable results.\n",
        "\n",
        "**Graded Task**: Fit a BMM model using the EM algorithm on the entire data (`X_all`).\n",
        "Use `K=2` and `num_iter=10` to cluster the data into 2 classes.\n",
        "Then, use `e_step` to compute the class responsibilities `Z`, for each data point.\n",
        "After you have computed `Z`, use the below code to print out some example reviews\n",
        "in each of the two classes. Do these classes correspond to positive/negative reviews?\n",
        "If not, how would you describe the difference between the two clusters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUiiBZ9kSNwQ",
        "outputId": "653294a2-156b-4d86-d00d-6e1152cff555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======= Samples From Class 0 =========\n",
            "this movie has some things that are pretty amazing first it is supposed to be based on a true story the problem was that by then you would be able to hear it\n",
            "lets start with the good things this is not a movie for kids the action scenes are great here too ok over to the things i didnt like thats that\n",
            "i enjoyed this movie as a kid when it came out and to this day still do i am surprised not too many people know about it cool flick\n",
            "i love this film it is well written and acted and has good cinematography see it buy it show it to your friends it still made me happy when everything worked out well in the end\n",
            "ever since i was a child this has been one of my favorite stories i want nothing from you why cant we be friends it is a moving performance and one of the movies most dramatic scenes not\n",
            "you want a friend get a dog at first all good no bad right everything goes to hell of course love that guy on some level i like that take the kids\n",
            "but the plot i heard was so great was so predictable plus the only cool character gets killed off in the middle of the movie wrong in short not much happens\n",
            "the end of an era its a shame that this movie is however not among their best the premise of the movie sounds good and is good most of the jokes in the movie still work good but the movie just however never gets truly hilarious or memorable\n",
            "it is a little known film even to die hard horror fans but i found this movie pretty entertaining dont get me wrong its certainly not without its problems but do think more people should give it a look i thought the acting which seemed forced at first somehow got better as the film went along it seems like the actors really got into their roles\n",
            "after all arent movies meant to be a good time the movie itself was an all around good time just dont expect to have to think too much about it because then if you take it too seriously then the movie actually wont be fun but stupid instead\n",
            "======= Samples From Class 1 =========\n",
            "im not sure i havent seen every episode but i still enjoyed it its hard to say which episode was my favorite\n",
            "this film has everything ask yourself are you a fan of and ive seen a lot of movies\n",
            "its not going to be the japanese version the show is great but\n",
            "i would love to see either of them in another movie\n",
            "this movie is great if you enjoy watching b class movies that is\n",
            "if you can do that it really is good s s s s i doubt it too bad\n",
            "first of all i want to point on screen play\n",
            "this is the best movie i have ever seen any movie that can get children to learn history is great\n",
            "but it is still dont care is it worth try it\n",
            "while by no means a classic the directors involved do have an idea what suspense is\n"
          ]
        }
      ],
      "source": [
        "pi, theta = em_bmm(X_all, K=2, num_iter=10) # TODO\n",
        "Z = e_step(X_all, pi, theta) # TODO\n",
        "\n",
        "classes = np.argmax(Z, axis=1)\n",
        "for k in range(Z.shape[1]):\n",
        "    print(\"======= Samples From Class\", k, \"=========\")\n",
        "    for i in np.where(classes == k)[0][:10]:\n",
        "        print(data[i][0])\n",
        "\n",
        "# TODO: Write your interpretation of the classes here\n",
        "# The reviews in the classes don't necessarily represent\n",
        "# positive or poor reviews. Class 0 seems to focus on\n",
        "# classics that are reviewed post release in a modern\n",
        "# context. Class 1 seems to contain foreign series,\n",
        "# /niche content that is not mainstream.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RglD_o9aSNwQ"
      },
      "source": [
        "**Graded Task**: Fit a BMM model using the EM algorithm on only the positive\n",
        "reviews (`X_pos`).\n",
        "Use `K=5` and `num_iter=10` to cluster the data into 5 classes.\n",
        "Then, use `e_step` to compute the class responsibilities `Z`, for each data point.\n",
        "After you have computed `Z`, use the below code to print out some example reviews\n",
        "in each of the five classes.\n",
        "\n",
        "Provide an interpretation for what these classes mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zKRiBccSNwQ",
        "outputId": "28fe8e49-febf-4407-e58a-6d5428f192da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-7c0444310987>:42: RuntimeWarning: divide by zero encountered in log\n",
            "  log_prob += np.log(theta[d, k])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Samples From Class 0 =========\n",
            "first of all i want to point on screen play\n",
            "things come to a head and one has to keep watching to follow up on such a sequence\n",
            "much to my surprise it wasnt about that at all\n",
            "he has no friends and all he wants to do is write and have someone like his writing\n",
            "i kept expecting it to fall apart but it never really did\n",
            "you know how its going to end but it has a great time getting there\n",
            "i dont know why its horrible what they did to the film\n",
            "but that scene will stay with you go for it\n",
            "he gets a chance to show off a bit i thought it was a good movie hes just hilarious you could do much much worse\n",
            "its not even close we need something different s s s version does have a better soundtrack than the original version s version\n",
            "======= Samples From Class 1 =========\n",
            "i would love to see either of them in another movie\n",
            "this movie is great if you enjoy watching b class movies that is\n",
            "if you can do that it really is good s s s s i doubt it too bad\n",
            "but it is still dont care is it worth try it\n",
            "good film thing is the film is named to kill for such a shame\n",
            "want action want more go out and buy this video\n",
            "i enjoyed this movie as a kid when it came out and to this day still do i am surprised not too many people know about it cool flick\n",
            "this is an average short but its still worth watching\n",
            "not a great film but certainly an enjoyable one its worth the effort\n",
            "i am not a very good writer so ill keep this short\n",
            "======= Samples From Class 2 =========\n",
            "im not sure i havent seen every episode but i still enjoyed it its hard to say which episode was my favorite\n",
            "this film has everything ask yourself are you a fan of and ive seen a lot of movies\n",
            "its not going to be the japanese version the show is great but\n",
            "this is the best movie i have ever seen any movie that can get children to learn history is great\n",
            "the film is unique in many ways this film will be two hours of your time well spent\n",
            "one of my most favorite films this is a real moment in time\n",
            "often feels like you are part of an audience at a stage show\n",
            "the end of an era its a shame that this movie is however not among their best the premise of the movie sounds good and is good most of the jokes in the movie still work good but the movie just however never gets truly hilarious or memorable\n",
            "and while this is yet another one it is different enough and well made that i still enjoyed it and many problems result\n",
            "that is a sad moment because it is too early for her to do an action she begins to fight against god mr who knows does she still have hope in her life the final scene gives us hope thats her hope\n",
            "======= Samples From Class 3 =========\n",
            "while by no means a classic the directors involved do have an idea what suspense is\n",
            "however the ending was really cool i say its must see i liked him lots i loved her rest of the cast do fine overall a must see\n",
            "i dont understand it really this is a good movie the supporting cast is good as well and the music in the movie is great its probably what makes the movie as enjoyable as it is\n",
            "he was both funny and sad the script worked well too\n",
            "but the plot i heard was so great was so predictable plus the only cool character gets killed off in the middle of the movie wrong in short not much happens\n",
            "the cast is first rate the film is a great deal of fun worth a look\n",
            "its a well acted film and it has a good beginning that gets you involved straight away its a good film\n",
            "well this is new the name mr youre a god mr\n",
            "the supporting cast are too good coming back everything was almost great except for the drama part\n",
            "while of course none of this is new it was enjoyable and well made\n",
            "======= Samples From Class 4 =========\n",
            "this movie has some things that are pretty amazing first it is supposed to be based on a true story the problem was that by then you would be able to hear it\n",
            "lets start with the good things this is not a movie for kids the action scenes are great here too ok over to the things i didnt like thats that\n",
            "i love this film it is well written and acted and has good cinematography see it buy it show it to your friends it still made me happy when everything worked out well in the end\n",
            "ever since i was a child this has been one of my favorite stories i want nothing from you why cant we be friends it is a moving performance and one of the movies most dramatic scenes not\n",
            "you want a friend get a dog at first all good no bad right everything goes to hell of course love that guy on some level i like that take the kids\n",
            "it is a little known film even to die hard horror fans but i found this movie pretty entertaining dont get me wrong its certainly not without its problems but do think more people should give it a look i thought the acting which seemed forced at first somehow got better as the film went along it seems like the actors really got into their roles\n",
            "after all arent movies meant to be a good time the movie itself was an all around good time just dont expect to have to think too much about it because then if you take it too seriously then the movie actually wont be fun but stupid instead\n",
            "i just love the movie the movie was excellent and its a very good actor so it deserves that and more there are some actors that do not act very well but have a oscar anyway it does not matter but he is perfect brilliant and beautiful\n",
            "i read the book before i saw the movie i knew the movie was going to be good because the book was great i seriously recommend you see this amazing fantastic movie i know you will like it\n",
            "i will be watching this movie many many more times find a friend who does and watch it there but for those times just boys got it today i hope some of it goes to girls\n"
          ]
        }
      ],
      "source": [
        "pi, theta = em_bmm(X_pos, K=5, num_iter=10) # TODO\n",
        "Z = e_step(X_pos, pi, theta) # TODO\n",
        "\n",
        "classes = np.argmax(Z, axis=1)\n",
        "for k in range(Z.shape[1]):\n",
        "    print(\"======= Samples From Class\", k, \"=========\")\n",
        "    for i in np.where(classes == k)[0][:10]:\n",
        "        print(data_pos[i][0])\n",
        "\n",
        "# TODO: Write your interpretation of the classes here\n",
        "\n",
        "# Class zero seems to again be the justification for the \\\n",
        "# movies niche nature. Positive in the sense of recognzing\n",
        "# what it set out to do.\n",
        "# Class one is a review focused on the positive qualities\n",
        "# of the film. It is full of positive adjectives which\n",
        "# detail the film's strengths.\n",
        "# Class two seems to be a review focused on the enjoyment\n",
        "# factor of the movie as a form of entertainment.\n",
        "# Class three seems to focus on the emotional impact\n",
        "# of the film as a contemplative work of art, as\n",
        "# well as the themes it tackles and how the audience\n",
        "# can relate to the characters.\n",
        "# Class four seems to deal with an indie horror/thriller\n",
        "# film possibly. The reception is lukewarm but, the\n",
        "# reviews understand that it is not the team's best work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUkHHEkYSNwR"
      },
      "source": [
        "**Task**: Fit a BMM model using the EM algorithm on only the negative\n",
        "reviews (`X_neg`).\n",
        "Use `K=5` and `num_iter=10` to cluster the data into 5 classes.\n",
        "Then, use `e_step` to compute the class responsibilities `Z`, for each data point.\n",
        "After you have computed `Z`, use the below code to print out some example reviews\n",
        "in each of the five classes.\n",
        "\n",
        "Provide an interpretation for what these classes mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PNWGt96mSNwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a47510-6251-4066-90ff-cb869c356574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Samples From Class 0 =========\n",
            "not good and not bad either hes a very good actor and should probably be an action star or something why do they make movies like this in the first place\n",
            "after all movies for free i told myself well hes done the good and the bad as far as films and tv go when they finally take off the effects are truly horrible but the horror doesnt stop there\n",
            "this has got to be one of the worst movies ive ever seen do they laugh when they create all this ridiculous stuff or do they actually think theyre doing something interesting i wonder its the best thing to do god\n",
            "all the way though i was thinking to myself oh god why why does going into the house make her come after you it doesnt make sense you can see everything coming which just left you feeling that there was no point in watching oh shes behind her\n",
            "the reviews i read for this movie were pretty decent so i decided to check it out bad idea and i didnt care about any of them perhaps a better writer could have made the movie work there were some decent scenes in it but overall this movie was a mess\n",
            "cinematography but why stop there the plot is just poor dialog is the less said the better characters dont get me started the more you think about this the worse it gets\n",
            "i dont really know where to start not only the acting was bad the characters were incredibly stupid as well then theres the action i believe that even children know that when someone gets shot theres blood involved times theres no blood at all well i guess thats just me to make a long story short because believe me i can go on for hours about this film this is without a doubt the worst film i ever saw\n",
            "in fact this is the his first film i have seen i am sure this movie is okay to watch as long as it is not taken too seriously\n",
            "dull characters there is nothing to her slow slow slow i am still watching the movie as i write this i cannot pay attention because it is boring\n",
            "great etc the list goes on and on and on i wanted to like this movie a thats it period and it could have worked whats that they wanted their film to be different right\n",
            "======= Samples From Class 1 =========\n",
            "this is quite simply one of the worst movies that i have ever seen in my life i know that even a low budget movie can be great but not this one what happens save your money and your time\n",
            "why is this one of the worst films ever come on mr\n",
            "this has got to be the worst horror movie i have ever seen avoid this movie\n",
            "i cant remember the worst film i have watched total waste of actors and audience time total waste of time\n",
            "this is the worst movie ive ever seen dont waste even a minute in your life to watch this crap they use only camera in hand dont make more movies\n",
            "its not only one of the worst movies ive seen but it is definitely the worst musical ive ever seen\n",
            "the worst think i have ever seen the worse film i have ever seen and i have seen some bad ones\n",
            "it may be the worst movie i have ever seen and i have seen a lot\n",
            "this was probably the worst movie ever seriously dont watch it i didnt even get all the way through this movie had to turn it off\n",
            "but other than that it was one of the worst films ever a must not see\n",
            "======= Samples From Class 2 =========\n",
            "you want a movie that leaves the audience on the side of the bad guys\n",
            "this is a great idea for a film but it unfortunately doesnt turn out to be a great movie\n",
            "i wanted this movie to work so badly but it just didnt\n",
            "she needs a man to help her the comedy too is not needed in a strong subject film like this even more so the comedy is simply not funny\n",
            "what were they thinking of terrible script terrible acting i dont even feel sorry for the actors i could go on and on\n",
            "am i right in thinking i went to see the same film as everyone else this film was terrible someone back me up\n",
            "i took it to my friend house to watch for movie night this movie was slow and the humor was forced dont see this movie\n",
            "at several points its difficult to know where this story is going\n",
            "really a terrible movie its to be expected though either way the movies pretty bad and dont watch it if theres anything better on\n",
            "im not sure what it is about him but i thought his mr theres that word again\n",
            "======= Samples From Class 3 =========\n",
            "i wanted to love this movie how could i not love it\n",
            "imagine what this film could have been like with a decent budget\n",
            "you know how it is well that is not true i just cant recommend this one\n",
            "a sorry i guess that part of your life isnt over yet get well soon you half a man\n",
            "but you can see it from here i definitely dont understand why anyone would recommend this movie no point to having made it really\n",
            "i dont understand what all of these beautiful women saw in him does this man have any shame what so ever what a mess of a movie\n",
            "etc save your money and your time not entertaining at all\n",
            "the book its wonderful its not a masterpiece but its more than just entertaining the movie do something else\n",
            "yes that made for an entertaining horror movie to be sure well forget all of that as this movie has nothing to do with that film\n",
            "no doubt she does but not in this film just a waste of movie time\n",
            "======= Samples From Class 4 =========\n",
            "the direction is terrible the acting is so so rest of the cast are average at best overall not worth your time or money\n",
            "there is just one word for this film some actors of quality have small parts in this film\n",
            "of course he has no idea what he is doing\n",
            "rock too bad the rest of the film could not have been as good as mr\n",
            "its very hard to think of a worse movie with such big name actors well\n",
            "there is nothing new here and i have another question\n",
            "the only star is for her the story itself then\n",
            "weak acting and very predictable nothing original about it but do not waste your time with this one\n",
            "and for the most part of the film not very funny\n",
            "this is a known fact mr one weak fight scene\n"
          ]
        }
      ],
      "source": [
        "pi, theta = em_bmm(X_neg, K=5, num_iter=10) # TODO\n",
        "Z = e_step(X_neg, pi, theta) # TODO\n",
        "\n",
        "classes = np.argmax(Z, axis=1)\n",
        "for k in range(Z.shape[1]):\n",
        "    print(\"======= Samples From Class\", k, \"=========\")\n",
        "    for i in np.where(classes == k)[0][:10]:\n",
        "        print(data_neg[i][0])\n",
        "\n",
        "# TODO: Write your interpretation of the classes here\n",
        "\n",
        "# Class zero seems to focus on the film's lack of\n",
        "# intrigue, and lost potential.\n",
        "\n",
        "# Class one seems to focus on the film's low-effort\n",
        "# nature. The cast seems disinterested and the plot\n",
        "# is innefective.\n",
        "\n",
        "# Class two focuses on the poor casting/script\n",
        "\n",
        "# Class three repeats that the movie is a waste\n",
        "# of time, and among the worst the audience has seen\n",
        "\n",
        "# Class four broadly covers how non-sensical\n",
        "# the actions of the cast are, and the poor composition\n",
        "# of the scenes/cinematography."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}